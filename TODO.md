

要储存的文件元数据
- 文件sha256
- 上传时间
- 文件大小
- 文件名
- 文件描述
- 文件作者
- 地图类型
- 地图版本(用datetime表示)



文件上传

单文件
1. 判断有没有sha256,有的话则直接去查存储,没有则等上传完在算一个sha256之后,再去查存储,存储里有了直接跳过,返回200直接msg里说已经存在一样的了,这个时候客户端该去调用put接口了,如果他想改文件元素据的话
2. 如果是没上传过的,直接把io.reader和元数据(元数据统统可空,sha256的话后端这边会重新算一遍)扔到存储里,后面的事情交给存储模块管

- 其实也可以通过这个接口上传大文件,但是看看能不能在上传之前有办法挡下太大的文件,例如50mb以上的

大文件拆分
1. 客户端调用`/upload/init`接口,前端自己选择chunk size和chunks,并带上一些其他的信息,例如文件名之类的并告诉后端 , 然后后端确定chunk size合适之后返回一个任务id(uuid之类的),此时后端创建`./tmp/{task_id}`文件夹准备接受chunk
2. 前端上传就通过/`upload/chunk`接口,上传用form-data body,携带分块内容,chunk index 和 task id,后端收到chunk后,chunk内容直接写到`./tmp/{task_id}`,然后此文件夹里还得有一个`metadata.json`存一些元素据,例如chunks,文件名之类的
3. 所有分块上传完毕后,前端调用`/upload/merge`接口,后端才开始合并chunk,并将合并后的文件内容写到存储里,并返回一个可访问url和元数据给前端,然后清空`./tmp/{task_id}`


cnb存储
- 准备一个公开的cnb仓库和可以访问此仓库token

1. 启动服务的时候,调用storage.InitCnb来初始化git仓库之类的,如果已经初始化(是否有commit了)过了就跳过init,顺便也测试一下token是否能用
2. 存储服务需要自己维护一个元数据db来快查这些内容,我选择sqlite,然后放在本地git工作区里,每次增删改的时候先去更新db,然后通过chan去吧文件内容推给管理git操作的goroutine,再等git操作的goroutine去吧内容推到cnb仓库上??(草,幂等怎么做啊草),InitCnb的时候会有3个goroutine去分别管
    - db定期同步到仓库
    - git操作
    git操作goroutine会使用chan接收是否有新文件需要被上传了,如果然后这个最好是有一个,是文件(包含db)否有更新,有更新且就push,更新之前会等待10秒看看还有没有请求进来,如果10s后没有请求进来了则直接推送, 如果有就再等2s。除此之外如果从chan接收到的文件10s内大于10个则立马完成git提交并push。若没有文件更新sleep
    每次git commit的commit title为具体到秒的datetime

3. save成功之后,会返回一个可以直接访问的cnb url给前端,
4. 需要做流控
